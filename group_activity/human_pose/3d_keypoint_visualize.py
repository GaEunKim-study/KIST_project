# -*- coding: utf-8 -*-
"""3D_keypoint_visualize.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wvPe-4L3wL3ExDRlPn_Ldcgj0s6nzEIA
"""

import matplotlib.pyplot as plt
from mpl_toolkits.mplot3d import Axes3D
import argparse
import imageio

import scipy.misc
from models import hmr, SMPL
import config
import constants
import torch
from torchvision.transforms import Normalize
import numpy as np
from utils.renderer import Renderer
from PIL import Image


parser = argparse.ArgumentParser()
parser.add_argument('--checkpoint', required=True, type=str,
                    help='Path to network checkpoint')
parser.add_argument('--img_path', required=True,
                    type=str, help='Testing image path')


def size_to_scale(size):
    if size >= 224:
        scale = 0
    elif 128 <= size < 224:
        scale = 1
    elif 64 <= size < 128:
        scale = 2
    elif 40 <= size < 64:
        scale = 3
    else:
        scale = 4
    return scale


def get_render_results(vertices, cam_t, renderer):
    rendered_people_view_1 = renderer.visualize(
        vertices, cam_t, torch.ones((images.size(0), 3, 224, 224)).long() * 255)
    return rendered_people_view_1

if __name__ == '__main__':
    args = parser.parse_args()
    img_path = args.img_path
    checkpoint_path = args.checkpoint

    normalize_img = Normalize(
        mean=constants.IMG_NORM_MEAN, std=constants.IMG_NORM_STD)
    device = torch.device(
        'cuda') if torch.cuda.is_available() else torch.device('cpu')

    hmr_model = hmr(config.SMPL_MEAN_PARAMS)
    checkpoint = torch.load(checkpoint_path)
    hmr_model.load_state_dict(checkpoint, strict=False)
    hmr_model.eval()
    hmr_model.to(device)

    smpl_neutral = SMPL(config.SMPL_MODEL_DIR, create_transl=False).to(device)
    img_renderer = Renderer(focal_length=constants.FOCAL_LENGTH,
                            img_res=constants.IMG_RES, faces=smpl_neutral.faces)
    '''
    temp_face = img_renderer.faces
    print(temp_face)
    print(temp_face.shape)   # (13776, 3)
    '''
    img = imageio.v2.imread(img_path)

    im_size = img.shape[0]
    im_scale = size_to_scale(im_size)
    #img_up = scipy.misc.imresize(img, [224, 224])
    img_up = np.array(Image.fromarray(img).resize([224, 224]))
    img_up = np.transpose(img_up.astype('float32'), (2, 0, 1)) / 255.0
    img_up = normalize_img(torch.from_numpy(img_up).float())
    images = img_up[None].to(device)

    with torch.no_grad():
        pred_rotmat, pred_betas, pred_camera, _ = hmr_model(
            images, scale=im_scale)
        pred_output = smpl_neutral(betas=pred_betas, body_pose=pred_rotmat[:, 1:],
                                   global_orient=pred_rotmat[:, 0].unsqueeze(1), pose2rot=False)
        pred_vertices = pred_output.vertices
        pred_joints = pred_output.joints
        pred_cam_t = torch.stack([pred_camera[:, 1],
                                  pred_camera[:, 2],
                                  2 * constants.FOCAL_LENGTH / (constants.IMG_RES * pred_camera[:, 0] + 1e-9)],
                                 dim=-1)
    

    import numpy as np
    import matplotlib.pyplot as plt
    keypoints_3d = []
    
    for i in range(0, 49):
        keypoints_3d.append(pred_joints[:, i, :].tolist())

    # 0이 얼굴의 중심(코), 1이 목
    # 0-7 (척추 부분?)
    # 1-5 (목 - 오른쪽 어깨)
    # 1-2 (목 - 왼쪽 어깨)
    # 5-6-7 (오른 팔)
    # 2-3-4 (왼쪽 팔)
    # 8이 꼬리뼈 (댜리 뻗어나오는 곳)
    # 8-13 -14(오른 다리)
    # 8-10 -11 (왼쪽 다리)
    I = np.array([ 1,  5, 6, 1, 1,  8,  10, 8,  13, 2, 3, 0])  # start points
    J = np.array([ 5,  6, 7, 2, 8,  10, 11, 13, 14, 3, 4, 1])  # end points

    fig = plt.figure(figsize=(20, 20))
    image_ax = fig.add_subplot(1, 2, 1)
    image_ax.imshow(img)
    ax = fig.add_subplot(1,2,2, projection='3d')
    RADIUS = 1 # space around the subject
    xroot, yroot, zroot = keypoints_3d[0][0][0], keypoints_3d[0][0][1], keypoints_3d[0][0][2]
    
    ax.set_xlim3d([-RADIUS+xroot, RADIUS+xroot])
    ax.set_ylim3d([-RADIUS+zroot, RADIUS+zroot])
    ax.set_zlim3d([-RADIUS-yroot, RADIUS-yroot])
    for i in range(0, 15):
        ax.scatter(keypoints_3d[i][0][0], keypoints_3d[i][0][2], -keypoints_3d[i][0][1])
    for i in range(len(I)):
        #ax.scatter(keypoints_3d[i][0][0], keypoints_3d[i][0][1], keypoints_3d[i][0][2])
        x, y, z = [np.array( [keypoints_3d[I[i]][0][j], keypoints_3d[J[i]][0][j]] ) for j in range(3)]
        #ax.plot(x, y, z, lw=2, color = (1, 0, 0))
        ax.plot(x, z, -y, lw=2, color = (1, 0, 0))
    plt.show()


    view_1 = get_render_results(pred_vertices, pred_cam_t, img_renderer)
    view_1 = view_1[0].permute(1, 2, 0).numpy()

    tmp = img_path.split('.')
    name_1 = '.'.join(tmp[:-2] + [tmp[-2] + '_view1'] + ['jpg'])

    imageio.imwrite(name_1, (view_1 * 255).astype(np.uint8))